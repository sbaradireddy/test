
import boto3
import base64
import os
import requests
import uuid
import smtplib
from email.mime.text import MIMEText
from msal import ConfidentialClientApplication

def lambda_handler(event, context):
    scopes = ['https://graph.microsoft.com/.default']

    # Azure AD App details
    CLIENT_ID = 'kg,jkhg'
    CLIENT_SECRET = 'mhgv,jhgv'
    TENANT_ID = 'jhfjhcfv'
	
    # AWS S3 bucket details
    S3_BUCKET = "pr-home-datascience/email_upload"
    
    # SMTP configuration
    SMTP_SERVER = "smtp.example.com"
    SMTP_PORT = 587
    SMTP_USERNAME = "your-email@example.com"
    SMTP_PASSWORD = "your-email-password"
    RECIPIENT_EMAIL = "recipient@example.com"

    # Set up MSAL
    authority = f'https://login.microsoftonline.com/{TENANT_ID}'
    app = ConfidentialClientApplication(CLIENT_ID, authority=authority, client_credential=CLIENT_SECRET)

    # Authenticate and get token
    result = app.acquire_token_for_client(scopes=scopes)
    access_token = result['access_token']

    graph_url = 'https://graph.microsoft.com/v1.0/users/HomeDSAWS@plymouthrock.com/mailFolders/inbox/messages'

    headers = {
        'Authorization': f'Bearer {access_token}',
        'Accept': 'application/json'
    }
    
    s3 = boto3.client('s3')

    def fetch_emails(graph_url):
        while graph_url:
            response = requests.get(graph_url, headers=headers)
            emails = response.json().get('value', [])
            process_emails(emails)
            
            # Check if there is another page of results
            graph_url = response.json().get('@odata.nextLink')
            print(graph_url)

    def process_emails(emails):
        print('emails count - ', len(emails))
        for email in emails:
            # Generate a unique UUID for folder name
            folder_name = str(uuid.uuid4()) + '/'
            
            try:
                response = s3.list_objects_v2(Bucket=S3_BUCKET, Prefix=folder_name)
                if 'Contents' in response or 'CommonPrefixes' in response:
                    print('Email already exists in bucket')
                    continue
                else:
                    s3.put_object(Bucket=S3_BUCKET, Key=folder_name+'/', Body=b'')
                    print(f"Folder {folder_name} created in Bucket")
                    
                    email_content = email['subject'] + email['body']['content']
                    
                    # Create a txt file with email subject and body in /tmp
                    filename = '/tmp/body.HTML'
                    with open(filename, 'w', encoding='utf-8') as file:
                        file.write(email_content)
                        
                    s3_key = f"{folder_name}/{os.path.basename(filename)}"
                    s3.upload_file(filename, S3_BUCKET, s3_key)
                    print(f"Uploaded email content as {filename} to S3")
            
            except Exception as e:
                print('An error occurred', e)
            
            # Fetch attachments
            attachments_url = f'https://graph.microsoft.com/v1.0/users/HomeDSAWS@plymouthrock.com/messages/{email["id"]}/attachments'
            response1 = requests.get(attachments_url, headers=headers)
            attachments = response1.json().get('value', [])
            
            for attachment in attachments:
                if '@odata.type' in attachment and attachment['@odata.type'] == '#microsoft.graph.fileAttachment':
                    attachment_content = base64.b64decode(attachment['contentBytes'])
                    attachment_name = '/tmp/' + attachment['name']
                    
                    # Save attachment in /tmp directory
                    with open(attachment_name, 'wb') as f:
                        f.write(attachment_content)
    
                    # Upload to S3
                    with open(attachment_name, 'rb') as f:
                        s3.upload_fileobj(f, S3_BUCKET, f"{folder_name}/{os.path.basename(attachment_name)}")
                    print(f"Uploaded {attachment_name} to S3")
            
            # Send an email notification after files are uploaded to S3
            send_notification_email(folder_name)

    def send_notification_email(folder_name):
        try:
            subject = "S3 Upload Notification"
            body = f"Files have been uploaded to the following S3 folder: {folder_name}"
            msg = MIMEText(body)
            msg["Subject"] = subject
            msg["From"] = SMTP_USERNAME
            msg["To"] = RECIPIENT_EMAIL

            with smtplib.SMTP(SMTP_SERVER, SMTP_PORT) as server:
                server.starttls()
                server.login(SMTP_USERNAME, SMTP_PASSWORD)
                server.sendmail(SMTP_USERNAME, RECIPIENT_EMAIL, msg.as_string())
                print(f"Notification email sent to {RECIPIENT_EMAIL}")
        except Exception as e:
            print(f"Error sending email: {e}")

    # Start fetching emails
    fetch_emails(graph_url)













import msal
import requests
import boto3
import base64
import os
#from datetime import datetime

def lambda_handler(event, context):
    scopes = ['https://graph.microsoft.com/.default']

    # Azure AD App details
    CLIENT_ID = 'kg,jkhg'
    CLIENT_SECRET = mhgv,jhgv'
    TENANT_ID = 'jhfjhcfv'
	
    # AWS S3 bucket details
    S3_BUCKET = "pr-home-datascience/email_upload"

    # Set up MSAL
    authority = f'https://login.microsoftonline.com/{TENANT_ID}'
    app = msal.ConfidentialClientApplication(CLIENT_ID, authority=authority, client_credential=CLIENT_SECRET)

    # Authenticate and get token
    result = app.acquire_token_for_client(scopes=scopes)
    access_token = result['access_token']

    graph_url = 'https://graph.microsoft.com/v1.0/users/HomeDSAWS@plymouthrock.com/mailFolders/inbox/messages'

    headers = {
        'Authorization': f'Bearer {access_token}',
        'Accept': 'application/json'
    }
    
    s3 = boto3.client('s3')
    
    def fetch_emails(graph_url):
        while graph_url:
            response = requests.get(graph_url, headers=headers)
            emails = response.json().get('value', [])
            process_emails(emails)
            
            # Check if there is another page of results
            graph_url = response.json().get('@odata.nextLink')
            print(graph_url)
            
    def process_emails(emails):
        # response = requests.get(graph_url, headers=headers)
        # emails_with_attachments = response.json().get('value', [])
        print('emails count - ',len(emails))
        for email in emails:
            email_id = email['id']
            split_email_id = email_id.split('-')
            if len(split_email_id) > 2:
                folder_name = split_email_id[2].rstrip('/') + '/'
            else:
                folder_name = email_id
            #folder_name=str(datetime.now())
            try:
                response = s3.list_objects_v2(Bucket=S3_BUCKET, Prefix=folder_name)
                if 'Contents' in response or 'CommonPrefixes' in response:
                    print('Email already exists in bucket')
                    continue
                else:
                    s3.put_object(Bucket=S3_BUCKET, Key=folder_name+'/',Body=b'')
                    print(f"Folder {folder_name} created in Bucket")
                    
                    email_content = email['subject'] + email['body']['content']
                    
                    # Create a txt file with email subject and body in /tmp
                    filename = '/tmp/body.HTML'
                    with open(filename, 'w', encoding='utf-8') as file:
                        file.write(email_content)
                        
                    s3_key = f"{folder_name}/{os.path.basename(filename)}"
                    s3.upload_file(filename, S3_BUCKET, s3_key)
                    print(f"Uploaded email content as {filename} to S3")
            
            except Exception as e:
                print('An error occurred', e)
            
            # Fetch attachments
            attachments_url = f'https://graph.microsoft.com/v1.0/users/HomeDSAWS@plymouthrock.com/messages/{email_id}/attachments'
            response1 = requests.get(attachments_url, headers=headers)
            attachments = response1.json().get('value', [])
            
            for attachment in attachments:
                if '@odata.type' in attachment and attachment['@odata.type'] == '#microsoft.graph.fileAttachment':
                    attachment_content = base64.b64decode(attachment['contentBytes'])
                    attachment_name = '/tmp/' + attachment['name']  # Use /tmp for Lambda's writable space
                    
                    # Save attachment in /tmp directory
                    with open(attachment_name, 'wb') as f:
                        f.write(attachment_content)
    
                    # Upload to S3
                    with open(attachment_name, 'rb') as f:
                        s3.upload_fileobj(f, S3_BUCKET, f"{folder_name}/{os.path.basename(attachment_name)}")
                    print(f"Uploaded {attachment_name} to S3")
            response = s3.list_objects_v2(Bucket=S3_BUCKET, Prefix=folder_name+'/')
            for obj in response['Contents']:
                print(obj['Key'])
                # s3.delete_object(Bucket=S3_BUCKET, Key=obj['Key'])
    
    # Start fetching emails
    fetch_emails(graph_url)
